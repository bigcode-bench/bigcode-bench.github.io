<!doctype html>
<html>
<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@100;400&display=swap" rel="stylesheet" />

<head>
    <meta charset="UTF-8" />
    <title>BigCodeBench Leaderboard</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.0/papaparse.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.3.3/dist/echarts.min.js"></script>
    <link rel="icon"
        href="https://cdn-avatars.huggingface.co/v1/production/uploads/1659521200179-5e48005437cb5b49818287a5.png" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/css/bootstrap.min.css" />

    <style>
        body {
            font-family: "JetBrains Mono", monospace;
            background-color: #ffffff;
            color: #000000;
        }

        #content {
            width: 75%;
        }

        th,
        td {
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
        }

        #notes {
            font-size: 1em;
        }

        #notes h3 {
            margin-top: 1em;
            font-size: 2em;
            text-align: center;
        }

        #notes li {
            font-size: 1.2em;
            font-weight: 300;
            margin: 1em;
        }

        .form-select {
            font-size: 1em;
        }

        table {
            table-layout: auto;
            width: 100%;
        }

        @media screen and (max-width: 1400px) {
            body {
                font-size: 1.6vw;
            }

            #content {
                width: 100%;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.6em;
            }

            h3 {
                font-size: 1.2em;
            }

            table {
                font-size: medium;
            }
        }
        /* Add this to your existing <style> section */
          .btn-group-lg > .btn, .btn-lg {
              padding: 0.5rem 1rem;
              font-size: 1.25rem;
              border-radius: 0.3rem;
          }
      
          .btn-outline-hard {
              color: #ff6b6b;
              border: 2px solid #ff6b6b;
              background-color: transparent;
          }
      
          .btn-outline-hard:hover,
          .btn-check:checked + .btn-outline-hard,
          .btn-outline-hard:active {
              color: #fff;
              background-color: #ff6b6b !important;
              border-color: #ff6b6b;
          }
      
          .btn-outline-full {
              color: #4ecdc4;
              border: 2px solid #4ecdc4;
              background-color: transparent;
          }
      
          .btn-outline-full:hover,
          .btn-check:checked + .btn-outline-full,
          .btn-outline-full:active {
              color: #fff;
              background-color: #4ecdc4 !important;
              border-color: #4ecdc4;
          }
    </style>
</head>

<body>
    <div id="content" class="container-fluid d-flex flex-column align-items-center gap-3">
        <h1 class="text-nowrap mt-5">üå∏ BigCodeBench Leaderboard</h1>
        <div class="alert alert-info border border-info p-4 text-center" style="background-color: #f8f9fa; max-width: 800px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
            <p class="mb-0 fw-bold" style="font-size: 1.3em;">
                üéâ Check out our latest work
                <br> 
                <a href="https://swe-arena.com" class="fw-bolder text-decoration-none"><u>SWE Arena</u></a>
                <br>
                Open Evaluation Platform on AI for Software Engineering,
                <br>
                featuring real-time code execution for any programs!
            </p>
        </div>
        <h3 class="fw-light text-nowrap">
            <small id="warning">BigCodeBench evaluates LLMs with <strong><u>practical</u></strong> and
                <strong><u>challenging</u></strong> programming tasks.<br /></small>
        </h3>
        <div class="d-flex flex-row justify-content-center gap-3">
            <a href="https://github.com/bigcode-project/bigcodebench"><img
                    src="https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white"
                    alt="github" class="img-fluid" /></a>
            <a href="https://huggingface.co/spaces/bigcode/bigcodebench-leaderboard"><img
                    src="https://img.shields.io/badge/huggingface-ü§ó_Leaderboard-yellow.svg?style=for-the-badge"
                    alt="leaderboard" class="img-fluid" /></a>
            <a href="https://arxiv.org/abs/2406.15877"><img
                    src="https://img.shields.io/badge/arXiv-2406.15877-b31b1b.svg?style=for-the-badge" alt="paper"
                    class="img-fluid" /></a>
            <a href="https://huggingface.co/blog/terryyz/bigcodebench-hard"><img
                    src="https://img.shields.io/badge/Blog-Hard-orange.svg?style=for-the-badge" alt="paper"
                    class="img-fluid" /></a>
        </div>
        <div class="btn-group btn-group-lg" role="group" id="Subset" style="margin-bottom: 10px;">
          <input type="radio" class="btn-check" name="subsetRadio" id="Hard" checked />
          <label class="btn btn-outline-hard" for="Hard">Hard</label>
          <input type="radio" class="btn-check" name="subsetRadio" id="Full" />
          <label class="btn btn-outline-full" for="Full">Full</label>
      </div>
        <div class="btn-group" role="group" id="Benchmark">
          <input type="radio" class="btn-check" name="btnradio" id="Complete" />
          <label class="btn btn-outline-primary" for="Complete">Complete</label>
          <input type="radio" class="btn-check" name="btnradio" id="Instruct" />
          <label class="btn btn-outline-primary" for="Instruct">Instruct</label>
          <input type="radio" class="btn-check" name="btnradio" id="Average" checked />
          <label class="btn btn-outline-primary" for="Average">Average</label>
      </div>
        <div class="form-check form-switch mt-3">
            <input class="form-check-input" type="checkbox" id="toggleUnknownSize">
            <label class="form-check-label" for="toggleUnknownSize">Show Models with Unknown Sizes</label>
        </div>
        <div id="chart" style="width: 100%; height: 600px"></div>
        <div class="container-fluid d-flex flex-row flex-nowrap">
            <div class="container-fluid d-flex flex-column align-items-center">
                <table id="origin" class="table table-responsive table-striped table-bordered flex-shrink-1 border border-3"></table>
            </div>
        </div>
        <div id="notes">
            <h3>üìù Notes</h3>
            <div class="inline-block mt-3">
                <ol>
                    <li>
                        Evaluated using
                        <a href="https://github.com/bigcode-project/bigcodebench-annotation/releases/tag/v0.1.0">BigCodeBench</a>;
                    </li>
                    <li>
                        Hard Set vs Full Set:
                        <br />
                        <strong>Hard Set</strong>: A subset of ~150 BigCodeBench tasks which is more user-facing and challenging.
                        <br />
                        <strong>Full Set</strong>: The full set of 1140 BigCodeBench tasks.
                    </li>
                    <li>
                        Models are ranked according to (calibrated) Pass@1 using greedy decoding. Setup details can be
                        found
                        <a href="https://github.com/bigcode-project/bigcodebench/blob/main/bigcodebench/generate.py">here</a>.
                    </li>
                    <li>
                        <i>Complete</i> vs <i>Instruct</i>:
                        <br />
                        <i><strong><u>Complete</u></strong></i>: Code Completion based on the structured long-context
                        docstring. This variant tests if the models are good at coding.
                        <br />
                        <strong><i><u>Instruct</u></i> (üî•Vibe Checküî•)</strong>: Code Generation based on the brief NL-oriented instructions. This variant tests if the models are really capable enough to
                        understand human intents to code.
                    </li>
                    <li>
                        Wonder the relative performance among models, or the current progress of task solve rate? Check
                        out the <u><a href="https://huggingface.co/spaces/bigcode/bigcodebench-leaderboard">ü§ó Hugging
                                Face Leaderboard</a></u>!
                    </li>
                    <li>
                        üí§ indicates the models having at least a difference of 1% between the calibrated Pass@1 and the
                        original one. What does this imply? Instruction-tuned models <u><a
                                href="https://community.openai.com/t/why-i-think-gpt-is-now-lazy">can be
                                lazy</a></u>, omitting essential code parts and thus failing on some tasks.
                        Therefore, we add the missing parts during evaluation, and report the calibrated Pass@1 score as
                        default,
                    <li>
                        ‚ú® marks models evaluated using a chat setting, while others perform direct code completion. We
                        note that some instruction-tuned models miss the chat template in their tokenizer configuration.
                    </li>
                    <li>
                        Model providers have the responsibility to avoid data contamination. Models trained on close data
                        can be affected by contamination.
                    </li>
                    <li>
                        üíö means open weights and open data. üíô means open weights and open SFT data, but the base model
                        is not data-open. What does this imply? üíöüíô models open-source the data such that one can
                        concretely reason about contamination.
                    </li>
                    <li>
                        "Size" here is the number of model parameters during inference.
                    </li>
                </ol>
            </div>
        </div>
        <div id="notes">
            <h3>ü§ó More Leaderboards</h3>
            In addition to BigCodeBench leaderboards, it is recommended to comprehensively understand LLM coding ability
            through a diverse set of benchmarks and leaderboards, such as:
            <div class="inline-block mt-3">
                <ol>
                    <li>
                        <a href="https://swe-arena.com/">SWE Arena</a>
                    </li>
                    <li>
                        <a href="https://evalplus.github.io/leaderboard.html">EvalPlus Leaderboard</a>
                    </li>
                    <li>
                        <a href="https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard">Spider 2.0</a>
                    </li>
                    <li>
                        <a href="https://spider2-sql.github.io">BigCodeBench Leaderboard</a>
                    </li>
                    <li>
                        <a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">Chatbot Arena
                            Leaderboard</a>
                    </li>
                    <li>
                        <a href="https://github.com/amazon-science/cceval">CrossCodeEval</a>
                    </li>
                    <li>
                        <a href="https://fudanselab-classeval.github.io/">ClassEval</a>
                    </li>
                    <li>
                        <a href="https://crux-eval.github.io/leaderboard.html">CRUXEval</a>
                    </li>
                    <li>
                        <a href="https://codetlingua.github.io/leaderboard.html">Code Lingua</a>
                    </li>
                    <li><a href="https://evo-eval.github.io/">Evo-Eval</a></li>
                    <li>
                        <a href="https://github.com/01-ai/HumanEval.jl">HumanEval.jl - Julia version HumanEval with
                            EvalPlus test cases</a>
                    </li>
                    <li>
                        <a href="https://infi-coder.github.io/inficoder-eval/">InfiCoder-Eval</a>
                    </li>
                    <li>
                        <a href="https://livecodebench.github.io/leaderboard.html">LiveCodeBench</a>
                    </li>
                    <li>
                        <a href="https://github.com/THUDM/NaturalCodeBench">NaturalCodeBench</a>
                    </li>
                    <li><a href="https://github.com/Leolty/repobench">RepoBench</a></li>
                    <li><a href="https://www.swebench.com/">SWE-bench</a></li>
                    <li>
                        <a href="https://leaderboard.tabbyml.com/">TabbyML Leaderboard</a>
                    </li>
                    <li>
                        <a href="https://github.com/alphadl/OOP-eval">OOP</a>
                    </li>
                </ol>
            </div>
        </div>

        <div id="notes">
            <h3>üôè Acknowledgements</h3>
            <div class="inline-block mt-3">
                <ul>
                    <li>
                        We thank the EvalPlus team for providing the leaderboard template.
                    </li>
                    <li>
                        We are grateful for the significant contributions from the BigCode community.
                    </li>
                </ul>
            </div>
        </div>
    </div>

    <script>
        const originTable = document.getElementById("origin");
        const benchmarkRadio = document.getElementById("Benchmark");
        const chartDom = document.getElementById("chart");
        const toggleUnknownSize = document.getElementById("toggleUnknownSize");
        var chart = echarts.init(chartDom);

        var dataUrl = "results-hard.json"; // Default data source
        var globalData;
        var currentSplit = "average"; // Track current split

        // Function to load data based on the selected subset
        function loadData() {
          var xhr = new XMLHttpRequest();
          xhr.open("GET", dataUrl, true);
          xhr.onload = function() {
              if (xhr.status === 200) {
                  globalData = JSON.parse(xhr.responseText);
                  globalData = Object.keys(globalData).map((key) => ({
                      Model: key,
                      ...globalData[key],
                      "pass@1": {
                          ...globalData[key]["pass@1"],
                          "average": calcAverage(globalData[key]["pass@1"]["complete"], globalData[key]["pass@1"]["instruct"])
                      }
                  }));
                  
                  // Reset chart data before displaying new data
                  resetChartData();
                  
                  displayTable(originTable, currentSplit);
                  displayChart(currentSplit, toggleUnknownSize.checked);
              } else {
                  alert("Failed to load data from " + dataUrl);
              }
          };
          xhr.send();
      }

        // Event listeners for the subset radio buttons
        document.getElementById("Hard").addEventListener("change", function () {
            if (this.checked) {
                dataUrl = "results-hard.json";
                loadData();
            }
        });

        document.getElementById("Full").addEventListener("change", function () {
            if (this.checked) {
                dataUrl = "results.json";
                loadData();
            }
        });

        // Initial data load
        loadData();

        const calcAverage = (a, b) => {
            if (a == null || b == null) {
                return null;
            } else {
                return parseFloat(((parseFloat(a) + parseFloat(b)) / 2).toFixed(1));
            }
        };

        const clearTable = () => {
            originTable.innerHTML = "";
        };

        const clearChart = () => {
            chartOption.xAxis.data = [];
            chartOption.series[0].data = [];
            chartOption.series[1].data = [];
            chartOption.series[0].markLine.data = [];
            chartOption.series[1].markLine.data = [];
        };

        const resetChartData = () => {
            // Reset all chart data structures
            chartOption.xAxis.data = [];
            chartOption.series[0].data = [];
            chartOption.series[1].data = [];
            chartOption.series[0].markLine.data = [];
            chartOption.series[1].markLine.data = [];
            chart.setOption(chartOption, true); // Force chart refresh
        };

        var chartOption = {
            legend: {
                data: ["pass@1*"],
            },
            grid: {
                left: "1%",
                right: "4%",
                bottom: "3%",
                containLabel: true,
            },
            xAxis: {
                name: "Size",
                type: "category",
                boundaryGap: false,
                data: [],
                axisLabel: {
                    formatter: function (value) {
                        return value + "B";
                    },
                },
            },
            yAxis: {
                name: "PASS@1 (greedy decoding)",
                type: "value",
                show: true,
                nameTextStyle: {
                    align: "left",
                },
                splitLine: {
                    show: true,
                    lineStyle: {
                        color: "gray",
                        type: "dashed",
                    },
                },
            },
            legend: {
                data: ["base", "instructed"],
                itemStyle: {
                    opacity: 1.0,
                },
            },
            tooltip: {
                trigger: "item",
                axisPointer: {
                    type: "cross",
                },
            },
            series: [
                {
                    name: "base",
                    type: "scatter",
                    data: [],
                    itemStyle: {
                        color: "#91cc75",
                        opacity: 0.2,
                    },
                    emphasis: {
                        focus: "series",
                    },
                    lineStyle: {
                        width: 2,
                    },
                    markLine: {
                        symbol: "none",
                        emphasis: {
                            label: {
                                position: "middle",
                                formatter: function (params) {
                                    return params.data.name;
                                },
                            },
                        },
                        data: [],
                    },
                },
                {
                    name: "instructed",
                    type: "scatter",
                    data: [],
                    itemStyle: {
                        color: "#5470c6",
                        opacity: 0.2,
                    },
                    emphasis: {
                        focus: "series",
                    },
                    lineStyle: {
                        width: 2,
                    },
                    markLine: {
                        symbol: "none",
                        emphasis: {
                            label: {
                                position: "middle",
                                formatter: function (params) {
                                    return params.data.name;
                                },
                            },
                        },
                        data: [],
                    },
                },
            ],
        };

        const theaders = ["Model", "Pass@1"];

        // score: 'complete', 'instruct', 'average'
        const displayTable = (table, score) => {
          // Clear existing table content
          table.innerHTML = '';
      
          // Filter out Null and sort data
          const data = globalData
              .filter((row) => row["pass@1"][score] != null)
              .sort((a, b) => b["pass@1"][score] - a["pass@1"][score]);
      
          // Create table header
          const thead = document.createElement("thead");
          const headerRow = document.createElement("tr");
          
          // Add rank header
          const rankHeader = document.createElement("th");
          rankHeader.textContent = "#";
          headerRow.appendChild(rankHeader);
          
          // Add other headers
          theaders.forEach(function (header) {
              const th = document.createElement("th");
              th.textContent = header;
              if (header == "Pass@1") {
                  th.style.backgroundColor = "#EEFFEE";
              }
              headerRow.appendChild(th);
          });
          thead.appendChild(headerRow);
          table.appendChild(thead);
      
          // Create table body
          const tbody = document.createElement("tbody");
          let previousScore = null;
          let actualRank = 1;
      
          data.forEach((row, index) => {
              const dataRow = document.createElement("tr");
              const rankCell = document.createElement("td");
      
              if (row["pass@1"][score] !== previousScore) {
                  actualRank = index + 1;
                  previousScore = row["pass@1"][score];
              }
      
              rankCell.textContent = actualRank;
              dataRow.appendChild(rankCell);
      
              const modelCell = document.createElement("td");
              modelCell.textContent = actualRank <= 3 ? ["ü•á ", "ü•à ", "ü•â "][actualRank - 1] : "";
      
              const modelLink = document.createElement("a");
              modelLink.href = row["link"];
              modelLink.textContent = row["Model"];
              modelLink.classList.add("link-underline-primary", "text-nowrap");
              modelCell.appendChild(modelLink);
              modelCell.classList.add("d-flex", "flex-nowrap");
      
              if (row["prompted"]) {
                  const promptedSymbol = document.createElement("span");
                  promptedSymbol.textContent = "‚ú®";
                  modelCell.appendChild(promptedSymbol);
              }
      
              // Add open-data and lazy symbols here if needed
      
              dataRow.appendChild(modelCell);
      
              const passCell = document.createElement("td");
              passCell.classList.add("text-nowrap");
              passCell.textContent = row["pass@1"][score] + (row["lazy"] ? "üí§" : "");
              passCell.style.backgroundColor = "#EEFFEE";
              passCell.style.fontWeight = "bold";
              dataRow.appendChild(passCell);
      
              tbody.appendChild(dataRow);
          });
      
          table.appendChild(tbody);
      };

        const displayChart = (score, showUnknownSize = true) => {
            // Reset chart data at the start
            resetChartData();
            
            // sort first
            let data = globalData
                .filter((model) => {
                    return model["pass@1"][score] != null;
                })
                .sort((a, b) => {
                    return b["pass@1"][score] - a["pass@1"][score];
                });

            if (!showUnknownSize) {
                data = data.filter((model) => model["size"] != null);
            }

            const sizeList = [
                ...new Set(
                    data
                    .filter((model) => model["size"] != null)
                    .map((model) => Math.round(model["size"])),
                ),
            ].sort((a, b) => {
                return a - b;
            });

            chartOption.xAxis.data = sizeList;
            chartOption.yAxis.max =
                1 + Math.max(...data.map((model) => model["pass@1"][score]));

            const nonPromptedModels = data.filter(
                (model) => model["prompted"] == false,
            );
            const promptedModels = data.filter(
                (model) => model["prompted"] == true,
            );

            [nonPromptedModels, promptedModels].forEach((series, idx) => {
                series.forEach((model) => {
                    if (model["size"] == null) {
                        chartOption.series[idx].markLine.data.push({
                            name: model["Model"],
                            yAxis: model["pass@1"][score],
                        });
                    } else {
                        chartOption.series[idx].data.push({
                            name: model["Model"],
                            value: [`${Math.round(model["size"])}`, model["pass@1"][score]],
                        });
                    }
                });
            });

            const offsets = [
                    [50, 0]
                ]
                .concat(Array.from({
                    length: sizeList.length - 2
                }, () => [0, 0]))
                .concat([
                    [-50, 0]
                ]);
            sizeList.forEach((size, idx) => {
                const bestNonPromptedModel = nonPromptedModels
                    .filter((model) => Math.round(model["size"]) == size)
                    .sort((a, b) => {
                        return b["pass@1"][score] - a["pass@1"][score];
                    })[0];
                const bestPromptedModel = promptedModels
                    .filter((model) => Math.round(model["size"]) == size)
                    .sort((a, b) => {
                        return b["pass@1"][score] - a["pass@1"][score];
                    })[0];
                const hightLightBest = (series, model) => {
                    const point = chartOption.series[series].data.find(
                        (point) => point.name == model["Model"],
                    );
                    point.itemStyle = {
                        opacity: 1.0,
                    };
                    point.label = {
                        show: true,
                        position: "top",
                        offset: offsets[idx],
                        formatter: function (params) {
                            return params.data.name;
                        },
                        color: "inherit",
                    };
                };
                if (bestNonPromptedModel) {
                    hightLightBest(0, bestNonPromptedModel);
                }
                if (bestPromptedModel) {
                    hightLightBest(1, bestPromptedModel);
                }
            });

            chart.setOption(chartOption);
        };

        const completeRadio = document.getElementById("Complete");
        const instructRadio = document.getElementById("Instruct");
        const averageRadio = document.getElementById("Average");

        completeRadio.addEventListener("click", function () {
            currentSplit = "complete";
            clearTable();
            displayTable(originTable, currentSplit);
            clearChart();
            displayChart(currentSplit, toggleUnknownSize.checked);
        });

        instructRadio.addEventListener("click", function () {
            currentSplit = "instruct";
            clearTable();
            displayTable(originTable, currentSplit);
            clearChart();
            displayChart(currentSplit, toggleUnknownSize.checked);
        });

        averageRadio.addEventListener("click", function () {
            currentSplit = "average";
            clearTable();
            displayTable(originTable, currentSplit);
            clearChart();
            displayChart(currentSplit, toggleUnknownSize.checked);
        });

        toggleUnknownSize.addEventListener("change", function () {
            const score = completeRadio.checked ? "complete" : instructRadio.checked ? "instruct" : "average";
            clearChart();
            displayChart(score, toggleUnknownSize.checked);
        });

        averageRadio.click();

        window.addEventListener("resize", () => {
            chart.resize();
        });
    </script>
</body>

</html>
